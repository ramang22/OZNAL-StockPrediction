{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\ramang\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\ramang\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "import time\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from PY_OZNAL_UTILS.oznal_utils import OZNAL_UTIL\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentense = \"Thank you very much, IAG goes up 9% in two days, we are beating C.I.T.A.D.E.L, Griffin fuck you.\"\n",
    "# lemmatizer = WordNetLemmatizer() \n",
    "# x = nltk.word_tokenize(sentense)\n",
    "# result = list(map(lemmatizer.lemmatize, x)) \n",
    "# if \"IAG\" in result:\n",
    "#     print(\"kap\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OZNAL = OZNAL_UTIL()\n",
    "# symbols = OZNAL.getStockSymbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #AAPL\n",
    "# start = datetime.datetime(2020,2,1)\n",
    "# end = datetime.datetime(2020,10,11)\n",
    "# OZNAL.downloadNASDAQHistoricalStockData(\"AAPL\", start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPost1 = pd.read_csv('r_wallstreetbets_posts_filter.csv') \n",
    "dfPost2 = pd.read_csv('wallstreetbets_posts_filter.csv')\n",
    "# dfComments = pd.read_csv('data/wallstreetbets_comments.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns2 = [\"id\", \"title\", \"score\", \"created_utc\", \"num_comments\", \"selftext\", \"upvote_ratio\"]\n",
    "df2 = dfPost2[columns2]\n",
    "columns = [\"id\", \"title\", \"score\", \"created_utc\", \"num_comments\"]\n",
    "df1 = dfPost1[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1119745 entries, 0 to 1127898\nData columns (total 11 columns):\n #   Column          Non-Null Count    Dtype  \n---  ------          --------------    -----  \n 0   id              1119745 non-null  object \n 1   title_x         937068 non-null   object \n 2   score_x         937069 non-null   float64\n 3   created_utc_x   937069 non-null   object \n 4   num_comments_x  937069 non-null   float64\n 5   title_y         699306 non-null   object \n 6   score_y         699307 non-null   float64\n 7   created_utc_y   699307 non-null   object \n 8   num_comments_y  699307 non-null   float64\n 9   selftext        420247 non-null   object \n 10  upvote_ratio    699307 non-null   float64\ndtypes: float64(5), object(6)\nmemory usage: 102.5+ MB\n"
     ]
    }
   ],
   "source": [
    "dfMerged = df1.merge(df2, on='id', how='outer')\n",
    "dfMerged  = dfMerged.drop_duplicates(subset=['id'], keep='last')\n",
    "dfMerged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n"
     ]
    }
   ],
   "source": [
    "def superFuc(row):\r\n",
    "    columnNames = [\"title\", \"score\", \"created_utc\", \"num_comments\"]\r\n",
    "    if row.name % 100000 == 0:\r\n",
    "        print(row.name)\r\n",
    "    for columnName in columnNames:\r\n",
    "        if row[columnName+\"_x\"] is np.nan:\r\n",
    "            row[columnName] = row[columnName+\"_y\"]\r\n",
    "        else:\r\n",
    "            row[columnName] = row[columnName+\"_x\"]\r\n",
    "    return row\r\n",
    "\r\n",
    "dfMerged = dfMerged.apply(lambda row: superFuc(row), axis=1)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged.to_csv('out.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged = dfMerged.drop(columns=['title_x','score_x','created_utc_x','num_comments_x','title_y','score_y','created_utc_y','num_comments_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged.to_csv('wallstreetbets_posts_all.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfPost1['created_utc'] = dfPost1['created_utc'].apply(lambda x : datetime.datetime.fromtimestamp(x))\n",
    "# df2 = dfPost1[dfPost1['created_utc'] > '2019-01-01 00:00:00']\n",
    "# df2.to_csv('r_wallstreetbets_posts_filter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfPost1['created_utc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATE, SYMBOL, FREQ, COUNT, UPVOTES, DOWNVOTES,  <- OPEN, HIGH, LOW, CLOSE, ADJ CLOSE, VOLUME"
   ]
  }
 ]
}