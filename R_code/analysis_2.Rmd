
```{r}
# imports
source("../R_code/OZNAL_utils.R")
library("readxl")
library(magrittr)
library(corrplot)
library(ggplot2)
library(nortest)
library(RColorBrewer)
library(tidyverse)
library(gridExtra)
library(knitr)
`%>%` <- magrittr::`%>%` # pipe operátor
```
 

## Hypotézy

Na zákldade dostupných dát a našich cielov sme identifikovali nasledovné hypotézy.

TODO Argumenty pre hypothesis-free vs hypothesis-driven vs endpointy

### Hypotéza 1 

Dokáže "Šum" na reddite ohľadom jedného symbolu ovplyvniť jeho rast na dennej baze (change)?

**Overenie** : Potvrdenie existencie korelácie medzi jednotlivými stĺpcami šumu a stĺpcom change, následne pomocou testu dokázať že sú závislé.  

### Hypotéza 2 

Ovplyní zmena hodnoty stocku sentiment jednotlivých príspevkov? 

**Overenie** : Potvrdenie existencie korelácie medzi stĺpcom change a stĺpcom sentiment, následne pomocou testu dokázať že sú závislé.  

### Hypotéza 3 

Čím je väčší "šum" na reddite tým je väčšia volume stocku? 

**Overenie** : Potvrdenie existencie korelácie mmedzi jednotlivými stĺpcami šumu a stĺpcom volume, následne pomocou testu dokázať že sú závislé.  

### Hypotéza 4 

Existuje súvislosť medzi rastúcimi stockmi, na základe "šumu" z redditu?

**Overenie** : Potvrdenie existencie korelácie mmedzi zmenou šumu a stĺpcami, ktoré reprezentujú hodnoty stocku, následne pomocou testu dokázať že sú závislé. 

### Hypotéza 5 
Dokáže reddit ovplyvniť rast stocku priebežne (v celých dátach) od 2019 do 2021? 

**Overenie** : Korelácia ???

### Hypotéza 6 

Dokáže reddit ovplyvniť rast stocku dopredu o týždeň? 

**Overenie** : Korelácia medzi šumom a maximálnou hodnotou stocku dopredu

## Základny opis dát

```{r}
df <- read.csv("../data/dataset_final.csv")
df <- df[,-2]
head(df)
```
```{r}
summary(df)
```
Finálny dataset obsahuje 98208 riadkov a má 25 stĺpcov. 

Taktiež sme sledovali či sú dáta z normálového rozdelnia pomocou Anderson-Darling testu. Tento test sme použili namiesto Shapiro–Wilk testu lebo dokáže pracovať aj s viac ako 5000 záznami. Pri použítí Anderson-Darlingu testu nám vyšlo že žiadne dáta niesu z normálovej distribúcie, takže to je prvý krok, ktorý budeme musiet vykonať pri čistený datasetu.

**Stĺpce sú nasledovné:**

* upvote_ratio - Tento stĺpec hovorí o pomere $upvote/downvote$ na príspevkoch pre jednen ticker v konkrétnom dni. 

* symbol - označenie akcie, ticker.

* date - timestamp, konkrétny deň.

* score - $count\_upvotes-count\_downvotes$, ako boli príspevky hodnotené.
 
```{r}
ad.test(df$score)
```
 
 
* awards - koľko krát boli dané príspevku, pre konkrétny ticker "boostnuté".

```{r}
ad.test(df$awards)
```


* sentiment - NLP hodnota, ktorá reprezentuje či príspevky a komentáre pre daný ticker mali pozitívny alebo negatívny sentiment.

```{r}
ad.test(df$sentiment)
```


* count - počet, ktorý hovorí o tom koľko krát bol daný ticker spomenutý v daný deň.

```{r}
ad.test(df$count)
```


* Open - otváracia cena akcie v daný deň.

```{r}
ad.test(df$Open)
```


* High - maximálna cena akcie v daný deň.

```{r}
ad.test(df$High)
```


* Low - minimálna cena akcie v daný deň.

```{r}
ad.test(df$Low)
```


* Close - zatváracia cena akcie v daný deň. 

```{r}
ad.test(df$Close)
```

* Adj.Close - stock price ktory je adjusted tak aby reflektovaö naozajstnu cenu

```{r}
ad.test(df$Adj.Close)
```

* Volume - cena predaných akcií v daný deň.

```{r}
ad.test(df$Volume)
```

* float - počet akcií 

```{r}
ad.test(df$float)
```

* spread - $High/Close$, rozsah zmeny ceny akcie v daný deň

```{r}
ad.test(df$spread)
```

* change - $Close/Open$, ako sa zmenila cena akcie v daný deň

```{r}
ad.test(df$change)
```

* peak - $High/Open$, o koľko narástla maximálna cena akcie v daný deň

```{r}
ad.test(df$peak)
```

* trough - $Open/Low$, o koľko klesla hodota akcie v daný deň

```{r}
ad.test(df$trough)
```

* min7 - minimálna hodnota akcie v uplynutých 7 dní

```{r}
ad.test(df$min7)
```

* max7 - maximálna hodnota akcie v uplynutých 7 dní

```{r}
ad.test(df$max7)
```

* min30 - minimálna hodota akcie v uplynutých 30 dní

```{r}
ad.test(df$min30)
```

* max30 - maximálna hodnota akcie v uplynutých 30 dní

```{r}
ad.test(df$max30)
```

* max7plus - maximálna cena akcie v nasledujúcich 7 dňoch

```{r}
ad.test(df$max7plus)
```

* min7plus - minimálna cena akcie v nasledujúcich 7 dňoch

```{r}
ad.test(df$min7plus)
```

* marketCap - hodna všetkých akcií konkrétneho tickera v daný deň

```{r}
ad.test(df$marketCap)
```
Vidíme zopár chýbajúcich hodnôt, ktoré budeme musiet v nasledujúcom kroku doplniť alebo odstrániť. Tieto hodnoty chýbajú z dôvodu spájania dát, pričom jednotlivé tickery neobsahovali hodnotu float.

```{r}
missing.values <- df %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing)) 
    
missing.values  %>% kable()
```
 

## Exploratory data analysis (EDA)

### Upvote Ratio

### Symbol

### Date

### Score

### Awards

### Sentiment

### Count

### Open

### High

### Low

### Close

### Adj.Close

### Volume

### Float

### Spread

### Change

### Peak

### Trough

### Min7 - days

### Max7 - days

### Min30 - days

### Max 30- days

### Max7Plus - days

### Min7Plus - days

### Marketcap

## Párová analýza

### Korelačná analýza

```{r}
dfCorr <- df[ , purrr::map_lgl(df, is.numeric)]
M <-cor(dfCorr)
corrplot(M, type="upper",
         col=brewer.pal(n=8, name="RdYlBu"))
```


### Score/Awards/Sentiments/Upvoteratio/Count vs Change

```{r}
pairs(~ score + awards + sentiment + upvote_ratio + count + change, data = df)
```
### Change/Spread/Trough/Peak vs Sentiment

```{r}
pairs(~ spread + trough + sentiment + peak + change, data = df)
```

### Score/Awards/Sentiments/Upvoteratio/Count vs Volume

```{r}
pairs(~ score + awards + sentiment + upvote_ratio + count + Volume, data = df)
```

### Plus Change vs Score/Awards/Sentiments/Upvoteratio/Count

```{r}
plusChange <- df[ which(df$change > 0), ]
pairs(~ score + awards + sentiment + upvote_ratio + count + change, data = plusChange)
```

## Prečo sú naše dáta reprezentatívne?

Dôvod prečo sú naše dáta reprezentatívne je nasledovný. Všetky dáta, s ktorými pracujeme sú realné dáta. Dáta z redditu sú získavané pomocou reddit API, takže to niesu žiadne fake data. Podobne aj s stock price, market dátami, ktoré sú tiež reálne. Takže všetky dáta sú realne, nič nieje vymyslené-fake data. Reprezentujú presné chovania stock marketu a zároveň aj správanie sa reddite.

## Prečo je náš dataset unikátny

Náš dataset je unikátny lebo je uplne novo vytvorený práve pre účel tohoto zadania. Tým že vznikol spojeným dvoch rôznych datasetov, pridaním údajov z yahoo finance a transformáciou do nami potrebného tvaru. 
