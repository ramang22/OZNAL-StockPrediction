{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "import time\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from PY_OZNAL_UTILS.oznal_utils import OZNAL_UTIL\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentense = \"Thank you very much, IAG goes up 9% in two days, we are beating C.I.T.A.D.E.L, Griffin fuck you.\"\n",
    "# lemmatizer = WordNetLemmatizer() \n",
    "# x = nltk.word_tokenize(sentense)\n",
    "# result = list(map(lemmatizer.lemmatize, x)) \n",
    "# if \"IAG\" in result:\n",
    "#     print(\"kap\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OZNAL = OZNAL_UTIL()\n",
    "# symbols = OZNAL.getStockSymbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #AAPL\n",
    "# start = datetime.datetime(2020,2,1)\n",
    "# end = datetime.datetime(2020,10,11)\n",
    "# OZNAL.downloadNASDAQHistoricalStockData(\"AAPL\", start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPost1 = pd.read_csv('r_wallstreetbets_posts_filter.csv') \n",
    "dfPost2 = pd.read_csv('wallstreetbets_posts_filter.csv')\n",
    "# dfComments = pd.read_csv('data/wallstreetbets_comments.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns2 = [\"id\", \"title\", \"score\", \"created_utc\", \"num_comments\", \"selftext\", \"upvote_ratio\"]\n",
    "df2 = dfPost2[columns2]\n",
    "columns = [\"id\", \"title\", \"score\", \"created_utc\", \"num_comments\"]\n",
    "df1 = dfPost1[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged = df1.merge(df2, on='id', how='outer')\n",
    "dfMerged  = dfMerged.drop_duplicates(subset=['id'], keep='last')\n",
    "dfMerged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def superFuc(row):\r\n",
    "    columnNames = [\"title\", \"score\", \"created_utc\", \"num_comments\"]\r\n",
    "    if row.name % 100000 == 0:\r\n",
    "        print(row.name)\r\n",
    "    for columnName in columnNames:\r\n",
    "        if row[columnName+\"_x\"] is np.nan:\r\n",
    "            row[columnName] = row[columnName+\"_y\"]\r\n",
    "        else:\r\n",
    "            row[columnName] = row[columnName+\"_x\"]\r\n",
    "    return row\r\n",
    "\r\n",
    "dfMerged = dfMerged.apply(lambda row: superFuc(row), axis=1)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfPost1['created_utc'] = dfPost1['created_utc'].apply(lambda x : datetime.datetime.fromtimestamp(x))\n",
    "# df2 = dfPost1[dfPost1['created_utc'] > '2019-01-01 00:00:00']\n",
    "# df2.to_csv('r_wallstreetbets_posts_filter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfPost1['created_utc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATE, SYMBOL, FREQ, COUNT, UPVOTES, DOWNVOTES,  <- OPEN, HIGH, LOW, CLOSE, ADJ CLOSE, VOLUME"
   ]
  }
 ]
}